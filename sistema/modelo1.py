# -*- coding: utf-8 -*-
"""Copia de nuevo_analisis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-NUK03Izo_WcXgq-dItXocSLwUlnnapj
"""

import numpy as np
import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
import joblib


#from google.colab import drive
import pandas as pd

# Monta tu Google Drive
#drive.mount('/content/drive')

# Define la ruta completa del archivo en Google Drive
#archivo ='/content/drive/MyDrive/modelo/Twitter_Data.csv' # Reemplaza con tu ruta
import os
# Lee el archivo CSV usando pandas
archivo="Twitter_Data.csv"
df = pd.read_csv(archivo)

df.head()

df

df = df[['category', 'clean_text']].copy()

df.head()

df['category'].hist()

target_map = {'Positivo': 1, 'Negativo': 0, 'Neutro': 2}
df['target'] = df['category'].map(target_map)

df.head()

df_train, df_test = train_test_split(df)

Y_train = df_train['target']
Y_test = df_test['target']

df_train

df_test

vectorizer = TfidfVectorizer(max_features=2000)

X_train = vectorizer.fit_transform(df_train['clean_text'])

X_train

X_test = vectorizer.transform(df_test['clean_text'])
X_test

Y_train = df_train['target']
Y_test = df_test['target']

model = LogisticRegression(max_iter=1000)
model.fit(X_train, Y_train)
print("Train acc:", model.score(X_train, Y_train))
print("Test acc:", model.score(X_test, Y_test))

P_train = model.predict(X_train)
P_test = model.predict(X_test)

cm = confusion_matrix(Y_train, P_train, normalize='true')
cm

def plot_cm(cm):
    classes = ['negativo', 'positivo', 'neutro']
    df_cm = pd.DataFrame(cm, index=classes, columns=classes)
    ax = sn.heatmap(df_cm, annot=True, fmt='g')
    ax.set_xlabel("prediccion")
    ax.set_ylabel("objetivo")
plot_cm(cm)

cm_test = confusion_matrix(Y_test, P_test, normalize='true')
plot_cm(cm_test)

word_index_map = vectorizer.vocabulary_
word_index_map

model.coef_[0]

corte = 4

print("Palabras más positivas:")
for word, index in word_index_map.items():
    weight = model.coef_[0][index]
    if weight > corte:
        print(word, weight)

print("Palabras más negativas:")
for word, index in word_index_map.items():
    weight = model.coef_[0][index]
    if weight < -corte:
        print(word, weight)

plt.hist(model.coef_[0], bins=30)

prueba = ["I feel sad", "Its lovely", "its good", "la"]

# Transformar la entrada con el vectorizador
x = vectorizer.transform(prueba)

# Predecir con el modelo
P = model.predict(x)

# Obtener las clases del modelo
clases = model.classes_

# Mostrar la clase predicha
for i in range (len(prueba)): #positivo': 1, 'negativo': 0, 'neutro': 2
    if clases[P[i]] == 0:
        print(f"el Comentario: '{prueba[i]}' es: negativo")
    if clases[P[i]] == 1:
        print(f"el Comentario: '{prueba[i]}' es: positivo")
    else:
        print(f"el Comentario: '{prueba[i]}' es: neutro")


joblib.dump(model,'modelo1.pkl')

joblib.dump(vectorizer, 'vectorizer.pkl')